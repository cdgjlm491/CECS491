{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim() :\n",
    "    # pull from huffington post data set\n",
    "    news = pd.read_json(\"huffPost.json\", lines = True)\n",
    "    #\n",
    "    news = news[[\"headline\", \"category\"]]\n",
    "    #\n",
    "    a = news[news[\"category\"] == \"BUSINESS\"]\n",
    "    b = news[news[\"category\"] == \"ENTERTAINMENT\"]\n",
    "    c = news[news[\"category\"] == \"FOOD & DRINK\"]\n",
    "    d = news[news[\"category\"] == \"HEALTHY LIVING\"]\n",
    "    e = news[news[\"category\"] == \"PARENTING\"]\n",
    "    \n",
    "    # combine topic frames\n",
    "    count = 5000\n",
    "    a = a[:count]\n",
    "    b = b[:count]\n",
    "    c = c[:count]\n",
    "    d = d[:count]\n",
    "    e = e[:count]\n",
    "    \n",
    "    frames = [a,b,c,d,e]\n",
    "    news = pd.concat(frames)\n",
    "        \n",
    "    idx = [i for i in range(len(news))]\n",
    "    news.insert(0, \"id\", idx)\n",
    "    news.set_index(\"id\", inplace = True)\n",
    "    \n",
    "    news.to_json(r'huffPost_v03.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    trim()\n",
    "    print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select() :\n",
    "    # pull from uci dataset\n",
    "    news = pd.read_csv(\"uci-news-aggregator.csv\")\n",
    "    news = news[[\"TITLE\", \"CATEGORY\"]]\n",
    "    #\n",
    "    b = news[news[\"CATEGORY\"] == 'b']\n",
    "    t = news[news[\"CATEGORY\"] == 't']\n",
    "    e = news[news[\"CATEGORY\"] == 'e']\n",
    "    h = news[news[\"CATEGORY\"] == 'm']\n",
    "    #\n",
    "    b[\"CATEGORY\"] = b[\"CATEGORY\"].replace(['b'], [\"business\"])\n",
    "    t[\"CATEGORY\"] = t[\"CATEGORY\"].replace(['t'], [\"science & tech\"])\n",
    "    e[\"CATEGORY\"] = e[\"CATEGORY\"].replace(['e'], [\"entertainment\"])\n",
    "    h[\"CATEGORY\"] = h[\"CATEGORY\"].replace(['m'], [\"health\"])\n",
    "    \n",
    "    # pull from huffington post data set\n",
    "    p_news = pd.read_json(\"huffPost.json\", lines = True)\n",
    "    p_news = p_news[[\"headline\", \"category\"]]\n",
    "    cols = {\"headline\" : \"TITLE\", \"category\" : \"CATEGORY\"}\n",
    "    #\n",
    "    p = p_news[p_news[\"category\"] == \"POLITICS\"]\n",
    "    p.rename(columns = cols, inplace = True)\n",
    "    p[\"CATEGORY\"] = p[\"CATEGORY\"].replace([\"POLITICS\"], ['politics'])    \n",
    "    #\n",
    "    trav = p_news[p_news[\"category\"] == \"TRAVEL\"]\n",
    "    trav.rename(columns = cols, inplace = True)\n",
    "    trav[\"CATEGORY\"] = trav[\"CATEGORY\"].replace([\"TRAVEL\"], ['travel'])     \n",
    "    \n",
    "    # combine topic frames\n",
    "    count = len(trav)\n",
    "    b = b[:count]\n",
    "    t = t[:count]\n",
    "    e = e[:count]\n",
    "    h = h[:count]\n",
    "    p = p[:count]\n",
    "    \n",
    "    frames = [b, t, e, h, p, trav]\n",
    "    news = pd.concat(frames)\n",
    "    \n",
    "    cols = {\"TITLE\" : \"title\", \"CATEGORY\" : \"topic\"}\n",
    "    news.rename(columns = cols, inplace = True)    \n",
    "    \n",
    "    idx = [i for i in range(len(news))]\n",
    "    news.insert(0, \"id\", idx)\n",
    "    news.set_index(\"id\", inplace = True)\n",
    "    \n",
    "    news.to_json(r'news_v02.json')\n",
    "    \n",
    "    #print(news.groupby([\"CATEGORY\"]).count())\n",
    "    #print(news.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter() :\n",
    "    news = pd.read_csv(\"uci-news-aggregator.csv\")\n",
    "    news = news[[\"TITLE\", \"CATEGORY\"]]\n",
    "\n",
    "    c = news[news[\"CATEGORY\"] == 'm']\n",
    "    c.count()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols() :\n",
    "    news = pd.read_csv(\"uci-news-aggregator.csv\")\n",
    "    news.drop(\"ID\", axis = 1, inplace = True)\n",
    "    news.drop(\"URL\", axis = 1, inplace = True)\n",
    "    news.drop(\"PUBLISHER\", axis = 1, inplace = True)\n",
    "    news.drop(\"STORY\", axis = 1, inplace = True)\n",
    "    news.drop(\"HOSTNAME\", axis = 1, inplace = True)\n",
    "    news.drop(\"TIMESTAMP\", axis = 1, inplace = True)\n",
    "    news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
